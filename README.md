# ToggleMaster - Fase 03 FIAP

Sistema completo de gerenciamento de feature flags com arquitetura de microsserviÃ§os, infraestrutura como cÃ³digo (Terraform), Kubernetes (EKS), GitOps com ArgoCD e pipelines DevSecOps.

##  VisÃ£o Geral

ToggleMaster Ã© uma plataforma de feature flags que permite:
- âœ… Gerenciamento centralizado de feature flags
- âœ… AvaliaÃ§Ã£o de flags em tempo real com cache Redis
- âœ… Targeting avanÃ§ado de usuÃ¡rios e segmentaÃ§Ã£o
- âœ… Analytics e monitoramento em tempo real
- âœ… AutenticaÃ§Ã£o e autorizaÃ§Ã£o JWT

## Como configurar a estrutura


### 1ï¸âƒ£ Configurar AWS CLI 

```bash
# Configurar AWS CLI
AWS_ACCESS_KEY_ID=<your-key>
AWS_SECRET_ACCESS_KEY=<your-secret>
AWS_DEFAULT_REGION=us-east-1
```

### 2ï¸âƒ£ Rodar o bootstrap para criar o Backend Terraform (S3 + DynamoDB)

```bash
cd terraform/bootstrap
terraform init
terraform apply -var-file=bootstrap.tfvars
```

### 3ï¸âƒ£ Deploy da Infraestrutura via Terraform

```bash
cd ../
terraform init
terraform plan
terraform apply
```

### 4ï¸âƒ£ Instalar ArgoCD

```bash
# Configurar kubectl
aws eks update-kubeconfig --name togglemaster --region us-east-1

# Instalar ArgoCD
./gitops/argocd/install.sh
```

### 5ï¸âƒ£ Obter Credenciais do ArgoCD

```bash
kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d
kubectl get svc argocd-server -n argocd
```

### 6ï¸âƒ£ Build & Push das Imagens (script local)

> O push para ECR Ã© feito manualmente com `scripts/build-push-ecr.sh`.
> Os workflows do GitHub Actions ficam apenas para validaÃ§Ã£o de CI (build/test/lint/security).

```bash
# Build & push de todos os serviÃ§os com a mesma tag
./scripts/build-push-ecr.sh all v1.0.0

```bash
# Verificar se as imagens jÃ¡ existem no ECR
aws ecr list-images --region us-east-1 --repository-name togglemaster/auth-service --query 'imageIds[*].imageTag'
aws ecr list-images --region us-east-1 --repository-name togglemaster/flag-service --query 'imageIds[*].imageTag'
aws ecr list-images --region us-east-1 --repository-name togglemaster/evaluation-service --query 'imageIds[*].imageTag'
aws ecr list-images --region us-east-1 --repository-name togglemaster/analytics-service --query 'imageIds[*].imageTag'
aws ecr list-images --region us-east-1 --repository-name togglemaster/targeting-service --query 'imageIds[*].imageTag'
```

### 7ï¸âƒ£ Deploy dos ServiÃ§os (GitOps)

```bash
# Aplicar as Applications do ArgoCD
kubectl apply -f gitops/apps/

# Verificar status das Applications
kubectl get applications -n argocd

# (Opcional) detalhes de uma aplicaÃ§Ã£o especÃ­fica
kubectl describe application auth-service -n argocd

# Verificar recursos no namespace da aplicaÃ§Ã£o
kubectl get all -n togglemaster
kubectl get pods -n togglemaster

# Acompanhar eventos (Ãºtil para ImagePullBackOff/ErrImagePull)
kubectl get events -n togglemaster --sort-by='.lastTimestamp'
```

### 8ï¸âƒ£ Ingress Controller via GitOps

```bash
# O app ingress-nginx estÃ¡ em gitops/apps e serÃ¡ aplicado junto com os outros
kubectl apply -f gitops/apps/

# Validar controller nginx
kubectl get applications -n argocd
kubectl get ingressclass
kubectl get svc -n ingress-nginx ingress-nginx-controller
```

### 9ï¸âƒ£ Validar Ingress da aplicaÃ§Ã£o

```bash
kubectl apply -f gitops/manifests/ingress/ingress.yaml
kubectl get ingress -n togglemaster -o wide
```

### ğŸ” Reset e Redeploy Limpo (quando precisar recriar tudo)

> Execute na raiz do repositÃ³rio (`Terraform-togglemaster`), nÃ£o dentro de `scripts/` ou `gitops/apps/`.

```bash
# 1) Remover Applications e namespace da aplicaÃ§Ã£o
kubectl delete -f gitops/apps/ --ignore-not-found=true
kubectl delete namespace togglemaster --ignore-not-found=true

# 2) Confirmar limpeza
kubectl get applications -n argocd
kubectl get ns togglemaster

# 3) Recriar via GitOps
kubectl apply -f gitops/apps/

# 4) (Opcional) aplicar manifests recursivamente
kubectl apply -R -f gitops/manifests/

# 5) Validar convergÃªncia
kubectl get applications -n argocd
kubectl get pods -n togglemaster
kubectl get jobs -n togglemaster
```
---

##  Arquitetura

### **MicrosserviÃ§os (5 serviÃ§os):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AWS Cloud (EKS)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Auth Service â”‚  â”‚ Flag Service â”‚  â”‚ Eval Service â”‚     â”‚
â”‚  â”‚   (Go)       â”‚  â”‚   (Python)   â”‚  â”‚   (Go)       â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â”‚                 â”‚                  â”‚              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ PostgreSQL  â”‚  â”‚  PostgreSQL  â”‚  â”‚  Redis Cache  â”‚    â”‚
â”‚  â”‚  (RDS)      â”‚  â”‚   (RDS)      â”‚  â”‚ (ElastiCache) â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Targeting Serviceâ”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤Analytics Service â”‚        â”‚
â”‚  â”‚   (Python)       â”‚  Queue  â”‚    (Python)      â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚         â”‚                             â”‚                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  PostgreSQL   â”‚            â”‚    DynamoDB     â”‚         â”‚
â”‚  â”‚    (RDS)      â”‚            â”‚   (NoSQL)       â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚           Amazon SQS (Message Queue)         â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚      Ingress (Load Balancer)       â”‚
         â”‚  analytics-service.togglemaster.io â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Stack**

- **Container Orchestration:** Kubernetes (Amazon EKS)
- **Infrastructure as Code:** Terraform
- **Container Registry:** Amazon ECR
- **Databases:** 
  - PostgreSQL (Amazon RDS) para Auth, Flag, Targeting
  - Redis (Amazon ElastiCache) para cache
  - DynamoDB para analytics
- **Message Queue:** Amazon SQS
- **CI/CD:** GitHub Actions
- **GitOps:** ArgoCD
- **Security:** Trivy, Bandit, gosec, golangci-lint

---

##  MicrosserviÃ§os

### **1. Auth Service** (Go)
- **Porta:** 8001
- **FunÃ§Ã£o:** AutenticaÃ§Ã£o e geraÃ§Ã£o de tokens JWT
- **Database:** PostgreSQL (RDS)
- **Endpoints:**
  - `POST /auth/login` - Login de usuÃ¡rios
  - `POST /auth/register` - Registro de novos usuÃ¡rios
  - `GET /auth/validate` - ValidaÃ§Ã£o de token

### **2. Flag Service** (Python)
- **Porta:** 8002
- **FunÃ§Ã£o:** CRUD de feature flags
- **Database:** PostgreSQL (RDS)
- **Endpoints:**
  - `GET /flags` - Listar flags
  - `POST /flags` - Criar flag
  - `PUT /flags/:id` - Atualizar flag
  - `DELETE /flags/:id` - Deletar flag

### **3. Evaluation Service** (Go)
- **Porta:** 8004
- **FunÃ§Ã£o:** AvaliaÃ§Ã£o de flags para usuÃ¡rios
- **Cache:** Redis (ElastiCache)
- **Queue:** Amazon SQS (eventos de avaliaÃ§Ã£o)
- **Endpoints:**
  - `POST /evaluate` - Avaliar flag para usuÃ¡rio
  - `GET /evaluate/bulk` - AvaliaÃ§Ã£o em lote

### **4. Targeting Service** (Python)
- **Porta:** 8003
- **FunÃ§Ã£o:** Regras de targeting de usuÃ¡rios
- **Database:** PostgreSQL (RDS)
- **Endpoints:**
  - `GET /targeting/rules` - Listar regras
  - `POST /targeting/rules` - Criar regra
  - `POST /targeting/match` - Verificar match de usuÃ¡rio

### **5. Analytics Service** (Python)
- **Porta:** 8005
- **FunÃ§Ã£o:** Coleta e anÃ¡lise de eventos
- **Database:** DynamoDB
- **Queue Consumer:** Amazon SQS
- **Endpoints:**
  - `GET /analytics/stats` - EstatÃ­sticas de uso
  - `GET /analytics/events` - Eventos registrados
  - `POST /analytics/query` - Query customizada

---

### **Recursos AWS Provisionados:**

#### **Compute:**
- âœ… Amazon EKS Cluster (Kubernetes 1.29)
- âœ… Node Group: 2x t3.medium (min: 1, max: 4)

#### **Databases:**
- âœ… 3x PostgreSQL RDS instances (db.t3.medium)
  - auth-service DB
  - flag-service DB
  - targeting-service DB
- âœ… Redis ElastiCache (cache.t3.micro)
- âœ… DynamoDB table (ToggleMasterAnalytics)

#### **Container Registry:**
- âœ… 5x ECR repositories (um por serviÃ§o)

#### **Networking:**
- âœ… VPC customizada (10.0.0.0/16)
- âœ… 2x Public Subnets
- âœ… 2x Private Subnets
- âœ… NAT Gateway
- âœ… Internet Gateway
- âœ… Security Groups

#### **Message Queue:**
- âœ… Amazon SQS Queue

### **Terraform Modules:**

```
terraform/
â”œâ”€â”€ main.tf           # Main configuration
â”œâ”€â”€ providers.tf      # AWS provider
â”œâ”€â”€ networking.tf     # VPC, subnets, NAT
â”œâ”€â”€ eks.tf           # EKS cluster
â”œâ”€â”€ database.tf      # RDS instances
â”œâ”€â”€ nosql.tf         # DynamoDB
â”œâ”€â”€ messaging.tf     # SQS
â”œâ”€â”€ registry.tf      # ECR repositories
â”œâ”€â”€ variables.tf     # Input variables
â””â”€â”€ outputs.tf       # Output values
bootstrap/
â”œâ”€â”€ bootstrap.tfvars          
â”œâ”€â”€ main.tf      # Main configuration
â””â”€â”€ variables.tf # Input variables

```

---

##  CI/CD & DevSecOps

### **Pipeline Stages:**

Cada microsserviÃ§o possui um pipeline completo com 4 jobs:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Build & Test â”‚
â”‚  - Compile      â”‚
â”‚  - Unit Tests   â”‚
â”‚  - Docker Build â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Linter       â”‚
â”‚  - flake8/Go    â”‚
â”‚  - Code Quality â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Security     â”‚
â”‚  - SAST         â”‚
â”‚  - SCA          â”‚
â”‚  âš ï¸ Block CRIT  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Docker Push  â”‚
â”‚  - Build Image  â”‚
â”‚  - Scan Image   â”‚
â”‚  - Push to ECR  â”‚
â”‚  - Update GitOpsâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Security Layers:**

1. **Linting:** flake8 (Python), golangci-lint (Go)
2. **SAST:** bandit (Python), gosec (Go)
3. **SCA:** Trivy filesystem scan
4. **Container Security:** Trivy image scan
5. **Blocking:** Pipeline fails on CRITICAL vulnerabilities

### **Workflows:**

- [analytics-service.yml](.github/workflows/analytics-service.yml)
- [auth-service.yml](.github/workflows/auth-service.yml)
- [evaluation-service.yml](.github/workflows/evaluation-service.yml)
- [flag-service.yml](.github/workflows/flag-service.yml)
- [targeting-service.yml](.github/workflows/targeting-service.yml)

---

##  GitOps com ArgoCD

### **Arquitetura GitOps:**

```
Developer â†’ GitHub â†’ CI Pipeline (validate)
        â†“
   build-push-ecr.sh â†’ ECR
        â†“
    ArgoCD â† monitors Git
                â†“
          Deploy to EKS
                â†“
     5 Microservices Running
```

### **Estrutura GitOps:**

```
gitops/
â”œâ”€â”€ apps/                      # ArgoCD Applications
â”‚   â”œâ”€â”€ analytics-service.yaml
â”‚   â”œâ”€â”€ auth-service.yaml
â”‚   â”œâ”€â”€ evaluation-service.yaml
â”‚   â”œâ”€â”€ flag-service.yaml
â”‚   â””â”€â”€ targeting-service.yaml
â”‚
â”œâ”€â”€ manifests/                 # Kubernetes manifests (Single Source of Truth)
â”‚   â”œâ”€â”€ namespace/
â”‚   â”œâ”€â”€ ingress/
â”‚   â”œâ”€â”€ analytics-service/
â”‚   â”‚   â”œâ”€â”€ configmap.yaml
â”‚   â”‚   â”œâ”€â”€ secret.yaml
â”‚   â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”‚   â”œâ”€â”€ service.yaml
â”‚   â”‚   â””â”€â”€ hpa.yaml
â”‚   â”œâ”€â”€ auth-service/
â”‚   â”œâ”€â”€ evaluation-service/
â”‚   â”œâ”€â”€ flag-service/
â”‚   â””â”€â”€ targeting-service/
â”‚
â””â”€â”€ argocd/
    â”œâ”€â”€ install.sh         # InstalaÃ§Ã£o automatizada
    â””â”€â”€ README.md
```

### **Fluxo de Deploy AutomÃ¡tico:**

1. **Code Change**: Developer faz push de cÃ³digo para `main`
2. **CI Pipeline**: GitHub Actions executa build, test, lint e security scans
3. **Image Publish**: `scripts/build-push-ecr.sh` publica as imagens no ECR com a tag de versÃ£o
4. **ArgoCD Sync**: ArgoCD sincroniza os manifests versionados do repositÃ³rio
5. **Kubernetes Deploy**: ArgoCD aplica manifestos no cluster EKS
6. **Verification**: Health checks validam deploy bem-sucedido


##  CI/CD Pipeline

### **Pipeline Stages:**

Cada microsserviÃ§o possui um pipeline completo:

```yaml
jobs:
  build_test:    # Build, compile, test
  lint:          # Code quality (flake8/golangci-lint)
  security:      # Security scans (gosec/bandit + Trivy)
  push_ecr:      # Build image â†’ Push to ECR
  update_gitops: # Update image tag in GitOps â†’ Triggers ArgoCD
```

### **Exemplo de Commit AutomÃ¡tico:**

ApÃ³s push de cÃ³digo, o pipeline:
1. Faz build da imagem com tag SHA (ex: `abc1234`)
2. Push para ECR
3. Atualiza automaticamente `gitops/manifests/auth-service/deployment.yaml`:
   ```yaml
   image: 913430344673.dkr.ecr.us-east-1.amazonaws.com/togglemaster/auth-service:abc1234
   ```
4. Faz commit: ` Update auth-service image to abc1234`
5. ArgoCD detecta e faz deploy automÃ¡tico

### **Security Layers:**

1. **Linting:** flake8 (Python), golangci-lint (Go)
2. **SAST:** bandit (Python), gosec (Go)
3. **SCA:** Trivy filesystem scan
4. **Container Security:** Trivy image scan
5. **Blocking:** Pipeline fails on CRITICAL vulnerabilities

---

### **Kubectl Direto:**

```bash
# Ver pods
kubectl get pods -n togglemaster

# Ver todos os recursos
kubectl get all -n togglemaster

# Ver logs
kubectl logs -n togglemaster -l app=auth-service --tail=50

# Logs em tempo real
kubectl logs -f -n togglemaster deployment/auth-service

# Descrever pod
kubectl describe pod <pod-name> -n togglemaster

# Executar comando em pod
kubectl exec -it <pod-name> -n togglemaster -- sh

# Port-forward para um serviÃ§o
kubectl port-forward -n togglemaster svc/auth-service 8001:8001

# Ver eventos
kubectl get events -n togglemaster --sort-by='.lastTimestamp'

# Ver configuraÃ§Ãµes
kubectl get configmap -n togglemaster
kubectl get secret -n togglemaster

# Escalar deployment
kubectl scale deployment/auth-service --replicas=3 -n togglemaster

# Ver HPA
kubectl get hpa -n togglemaster
```

### **Monitoramento:**

```bash
# Ver recursos consumidos
kubectl top nodes
kubectl top pods -n togglemaster

# MÃ©tricas de um pod especÃ­fico
kubectl describe pod <pod-name> -n togglemaster | grep -A 5 "Limits\|Requests"

# Ver status de health
kubectl get pods -n togglemaster -o wide

# Restart deployment (recreate pods)
kubectl rollout restart deployment/auth-service -n togglemaster

# Ver histÃ³rico de rollouts
kubectl rollout history deployment/auth-service -n togglemaster

# Rollback
kubectl rollout undo deployment/auth-service -n togglemaster
```

# Verificar secret
kubectl get secret ecr-secret -n togglemaster -o yaml

# Recriar secret
kubectl delete secret ecr-secret -n togglemaster
kubectl create secret docker-registry ecr-secret \
  --docker-server=913430344673.dkr.ecr.us-east-1.amazonaws.com \
  --docker-username=AWS \
  --docker-password=$(aws ecr get-login-password --region us-east-1) \
  --namespace=togglemaster

### **Em caso de problema vocÃª pode verificar:**

### **ArgoCD nÃ£o sincroniza:**

```bash
# Verificar status da aplicaÃ§Ã£o
kubectl get applications -n argocd

# Ver detalhes
kubectl describe application auth-service -n argocd

# ForÃ§ar sincronizaÃ§Ã£o (se usando ArgoCD CLI)
argocd app sync auth-service

# Ou via UI: Clicar em "Sync" â†’ "Synchronize"
```

### **Erro de permissÃ£o AWS:**

```bash
# Verificar credenciais AWS
aws sts get-caller-identity

# Verificar se tem acesso ao ECR
aws ecr describe-repositories --region us-east-1

# Verificar se tem acesso ao EKS
aws eks describe-cluster --name togglemaster --region us-east-1
```

### **Pod fica em Pending:**

```bash
# Ver por que estÃ¡ pending
kubectl describe pod <pod-name> -n togglemaster

# Causas comuns:
# - Recursos insuficientes: Aumentar nodes ou reduzir requests
# - ImagePullBackOff: Ver seÃ§Ã£o acima
# - PVC nÃ£o bound: Verificar PersistentVolumeClaims
```

### **Logs Ãºteis para debug:**

```bash
# Logs do kubelet (nos workers)
kubectl logs -n kube-system -l component=kubelet

# Logs do scheduler
kubectl logs -n kube-system -l component=kube-scheduler

# Logs do controller manager
kubectl logs -n kube-system -l component=kube-controller-manager

# Eventos do cluster
kubectl get events --all-namespaces --sort-by='.lastTimestamp'
```

### **Para destruir a infraestrutura via terraform:**

### **Destroy:**

```bash
cd terraform

# Destroy all AWS resources
terraform destroy

# Or destroy specific resources
terraform destroy -target=aws_eks_cluster.main
```

**âš ï¸ Warning:** vai deletar todos os recursos criados:
- EKS cluster
- All databases (data loss!)
- ECR images
- DynamoDB tables
- All networking resources
---

